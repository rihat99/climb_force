<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- <meta name="description" content="DESCRIPTION META TAG"> -->
  <!-- <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/> -->
  <!-- <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/> -->
  <!-- <meta property="og:url" content="URL OF THE WEBSITE"/> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
  <!-- <meta property="og:image:width" content="1200"/> -->
  <!-- <meta property="og:image:height" content="630"/> -->


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG"> -->
  <!-- <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE"> -->
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->


  <title>Climber Force and Motion Estimation from Video</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Climber Force and Motion Estimation from Video</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=Pm32NBYAAAAJ&hl=en" target="_blank">Rikhat Akizhanov</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/jason-banks-5a555b168/" target="_blank">Jason J. Banks</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.it/citations?user=kA_l7GYAAAAJ&hl=it" target="_blank">Fabio Pizzati</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=AsTKtBcAAAAJ&hl=en" target="_blank">Peter Wolf</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=kzFmAkYAAAAJ&hl=en" target="_blank">Pascal Fua</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=-9ifK0cAAAAJ&hl=en" target="_blank">Ivan Laptev</a><sup>1</sup>,</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>MBZUAI, <sup>2</sup>ETH, <sup>3</sup>EPFL</span>
              <span class="conf-block"><br>(Abstract) 2025</span>
              <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div>

            <!-- <div class="column has-text-centered">
            <div class="publication-links">
        
              <span class="link-block">
                <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                  <span>Paper</span>
                </a>
              </span>

           
              <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                  <span>Supplementary</span>
                </a>
              </span>

            
              <span class="link-block">
                <a href="https://github.com/YOUR REPO HERE" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                  <span>Code</span>
                </a>
              </span>

           
              <span class="link-block">
                <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
            </div> -->
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Estimated Contact Forces and Joint Torques Projected on Video</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="60%">
  
            <source src="static/videos/03_laddering1_project.mov"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="60%">

            <source src="static/videos/08_swinging_project.mov"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->

<!-- Video Section -->
<section class="hero is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <h2 class="title is-3 has-text-centered">
        Estimated Contact Forces and Joint Torques Projected on Video
      </h2> -->
      <div class="columns is-centered">
        <!-- Video 1 -->
        <div class="column">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/03_laddering1_project.mp4" type="video/mp4">
          </video>
        </div>
        <!-- Video 2 -->
        <div class="column">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/08_swinging_project.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!-- Single Description -->
      <h2 class="subtitle has-text-centered mt-4">
        Contact forces generated by climber are shown as red arrows. Torques on each climber's joint is proportional to green circle size.
      </h2>
    </div>
  </div>
</section>
<!-- End Video Section -->

<!-- Paper abstract -->
<!-- <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Accurately estimating climber motion and contact forces is essential for performance evaluation and judging. Traditional methods using force sensors or motion capture systems provide precise data but lack scalability and require controlled environments. This study proposes a vision-only approach to estimate motion and contact forces without additional instrumentation. Our method extracts 2D and 3D pose trajectories, estimates contact timings under a rigid contact assumption, and optimizes for force estimation and trajectory refinement while enforcing physical constraints. Validation against force sensor data shows that while the rigid contact model introduces some non-smooth variations, overall force trends are well captured, and motion smoothness improves through optimization. The results demonstrate the feasibility of a scalable, vision-based approach for climbing analysis, with future work focusing on refining the contact model and expanding applicability across diverse climbing techniques.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End paper abstract -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">

          <p><strong>Motivation</strong></p>
          <p>
            Climbing performance is subject to subtle differences in exerted forces and motion of the body. Traditional methods for human force and motion estimation typically use dedicated sensors and provide precise measurements but require controlled environments and expensive setups. Instead, we propose to estimate body motion, forces, and torques directly from a single camera using no specialized equipment. This problem, however, is challenging as forces are not directly observable and must be inferred from the motion. Our approach combines vision-based human pose estimation with physics-based reasoning and derives accurate forces and torques from climbing videos.
          </p>
          <p><strong>Approach</strong></p>
          <p>
            We build on recent advances in computer vision and first estimate 2D human pose (Khirodkar et al. 2024) for each frame of the video. These estimates are lifted to 3D to compute joint motions and forces.  Contact interactions with the climbing surface are then modeled under the assumptions of rigid and non-sliding support and known body mass distribution. Finally, similar to Li et al. 2022, we rely on inverse dynamics to refine all our estimates. By enforcing the consistency between motion, forces, and torques, we improve the precision for both (i) force estimates and (ii) trajectories of human body joints.
          </p>
          <p><strong>Results</strong></p>
          <p>
            We evaluate our method on videos with people climbing a campus board. The campusboard is equipped with four force sensors and provides ground truth force measurements at contacts. The comparison of automatically estimated forces with the ground truth reveals high accuracy of our method for different people and climbing styles. Qualitative and quantitative results of our method together with further details on the experimental setup are available at https://rihat99.github.io/climb_force.
          </p>
          <p><strong>Conclusion</strong></p>
          <p>
            This study presents an easy-to-deploy vision-based method to estimate climber motion and contact forces without specialized hardware. Results indicate that our approach effectively reconstructs force trends and improves 3D human motion estimation. We believe our work will support more efficient climber training and will help to develop Video Assistant Referee (VAR) systems for climbing competitions. Our future efforts will focus on refining contact models and improving force estimation for both indoors and outdoors environments.
          </p>
          <p><strong>References</strong></p>
          <p>
            Khirodkar, R., Bagautdinov, T., Martinez, J., Zhaoen, S., James, A., Selednik, P., Anderson, S., & Saito, S. (2024). Sapiens: Foundation for human vision models. Lecture Notes in Computer Science, 206–228. https://doi.org/10.1007/978-3-031-73235-5_12
          </p>
          <p>
            Li, Z., Sedlar, J., Carpentier, J., Laptev, I., Mansard, N., & Sivic, J. (2022). Estimating 3D motion and forces of human–object interactions from internet videos. International Journal of Computer Vision, 130(2), 363–383. https://doi.org/10.1007/s11263-021-01540-1
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image Section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Comparion of Estimated Force with Sensor Data</h2>

      <!-- First Row: Single Centered Image -->
      <div class="columns is-centered">
        <div class="column is-half has-text-centered">
          <img src="static/images/total_force.png" alt="Total force applied by climber on the wall" style="width: 100%; max-width: 600px;">
          <h2 class="subtitle has-text-centered mt-2">
            Total force applied by climber on the wall.
          </h2>
        </div>
      </div>

      <!-- Second Row: Two Images Side by Side -->
      <div class="columns is-centered">
        <div class="column is-half has-text-centered">
          <img src="static/images/left_hand_force.png" alt="Left hand force applied by climber on the wall" style="width: 100%; max-width: 600px;">
          <h2 class="subtitle has-text-centered mt-2">
            Left hand force applied by climber on the wall.
          </h2>
        </div>
        <div class="column is-half has-text-centered">
          <img src="static/images/right_hand_force.png" alt="Right hand force applied by climber on the wall" style="width: 100%; max-width: 600px;">
          <h2 class="subtitle has-text-centered mt-2">
            Right hand force applied by climber on the wall.
          </h2>
        </div>
      </div>

    </div>
  </div>
</section>
<!-- End Image Section -->

<!-- Video Section -->
<section class="hero is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <h2 class="title is-3 has-text-centered">
        Estimated Contact Forces and Joint Torques Projected on Video
      </h2> -->
      <div class="columns is-centered">
        <!-- Video 1 -->
        <div class="column">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/03_laddering1_compar.mp4" type="video/mp4">
          </video>
        </div>
        <!-- Video 2 -->
        <div class="column">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/08_swinging_compar.mp4" type="video/mp4">
          </video>
        </div>
      </div>
      <!-- Single Description -->
      <h2 class="subtitle has-text-centered mt-4">
        SMPL model projected on video, showing accurate shape and position estimation (left), side view of the same motion (right).
      </h2>
    </div>
  </div>
</section>
<!-- End Video Section -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
